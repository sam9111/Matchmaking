{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samyuktha/PPAI-MatchAPI/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "categories = [\n",
    "    \"Computer Science\", \"Electrical Engineering\", \"Mechanical Engineering\", \"Civil Engineering\", \"Biomedical Engineering\", \"Environmental Science\", \"Mathematics\", \"Chemistry\", \"Physics\", \"Aerospace Engineering\", \"Data Science\", \"Information Technology\", \"Robotics\", \"Geology\", \"Biochemistry\", \"Education\", \"Environment\", \"Health and Wellness\", \"Social Justice\", \"Poverty Alleviation\", \"Community Development\", \"Humanitarian Aid\", \"Arts and Culture\", \"Elderly Care\", \"Animal Welfare\", \"LGBTQ+ Support\", \"Food Security\", \"Youth Empowerment\", \"Clean Water and Sanitation\", \"Disabilities Support\"\n",
    "]\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize and encode the categories\n",
    "encoded_categories = [tokenizer(category, return_tensors='pt') for category in categories]\n",
    "\n",
    "# Extract embeddings from BERT\n",
    "category_embeddings = []\n",
    "\n",
    "for category in encoded_categories:\n",
    "    output = model(**category)\n",
    "    embeddings = output.last_hidden_state[:, 0, :]\n",
    "    category_embeddings.append(embeddings)\n",
    "\n",
    "# Convert to torch tensors\n",
    "\n",
    "category_embeddings = torch.cat(category_embeddings, dim=0)\n",
    "\n",
    "# Calculate cosine similarity between categories\n",
    "\n",
    "cosine_similarities = cosine_similarity(category_embeddings.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save top 5 most similar categories for each category without itself to json\n",
    "\n",
    "similar_categories = {}\n",
    "\n",
    "for i in range(len(categories)):\n",
    "\n",
    "    # Sort the categories by similarity\n",
    "    similar_categories[categories[i]] = [categories[x] for x in cosine_similarities[i].argsort()[-6:-1][::-1]]\n",
    "\n",
    "# Save to json\n",
    "\n",
    "import json\n",
    "\n",
    "with open('similar_categories.json', 'w') as fp:\n",
    "    json.dump(similar_categories, fp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading Faker-19.11.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in ./.venv/lib/python3.11/site-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Downloading Faker-19.11.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faker\n",
      "Successfully installed faker-19.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import card_data and generate a list of objects with a random name and random categories and random skills and interests under them\n",
    "import faker\n",
    "import random\n",
    "import json\n",
    "\n",
    "with open('card_data.json') as json_file:\n",
    "\n",
    "    card_data = json.load(json_file)\n",
    "\n",
    "# Generate a list of objects with a random name and random categories and random skills and interests under them\n",
    "\n",
    "random_mentors = {}\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    # Generate a random name\n",
    "    name = faker.Faker().name()\n",
    "\n",
    "    # Generate random categories\n",
    "    categories = random.sample(list(card_data.keys()), 2)\n",
    "\n",
    "    # Generate random skills and interests\n",
    "    skills = []\n",
    "    interests = []\n",
    "\n",
    "    for category in categories:\n",
    "        skills += random.sample(card_data[category][\"skills\"], 3)\n",
    "        interests += random.sample(card_data[category][\"interests\"], 3)\n",
    "\n",
    "    # Append to random_cards\n",
    "    random_mentors[name] = {\n",
    "        \"categories\": categories,\n",
    "        \"skills\": skills,\n",
    "        \"interests\": interests\n",
    "    }\n",
    "\n",
    "# Save to json\n",
    "\n",
    "with open('random_mentors.json', 'w') as fp:\n",
    "\n",
    "    json.dump(random_mentors, fp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a list of skills/interests/categories, find the most similar mentor from random_mentors\n",
    "\n",
    "# Load random_mentors\n",
    "\n",
    "with open('random_mentors.json') as json_file:\n",
    "\n",
    "    random_mentors = json.load(json_file)\n",
    "\n",
    "sample_mentee=[\n",
    "    \"Computer Science\",\n",
    "    \"Artificial Intelligence\",\n",
    "    \"Cybersecurity\",\n",
    "    \"Machine Learning\",\n",
    "    \"Community Development\",\n",
    "    \"Housing Development\",\n",
    "    \"Infrastructure Improvement\",\n",
    "    \"Affordable Housing\",\n",
    "    \"Data Science\",\n",
    "    \"Data Visualization\",\n",
    "    \"Machine Learning\",\n",
    "    \"Big Data Technologies\",\n",
    "    \"Arts and Culture\",\n",
    "    \"Art Therapy\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('card_data.json') as json_file:\n",
    "\n",
    "    card_data = json.load(json_file)\n",
    "\n",
    "\n",
    "everything = []\n",
    "\n",
    "for category in card_data.keys():\n",
    "    everything.append(category)\n",
    "    everything += card_data[category][\"skills\"]\n",
    "    everything += card_data[category][\"interests\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector(sample):\n",
    "\n",
    "    sample_indices = []\n",
    "\n",
    "    for element in sample:\n",
    "\n",
    "        sample_indices.append(everything.index(element))\n",
    "\n",
    "    # at each index, put 1\n",
    "\n",
    "    sample_vector = [0] * len(everything)\n",
    "\n",
    "    for index in sample_indices:\n",
    "\n",
    "        sample_vector[index] = 1\n",
    "\n",
    "    return sample_vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mentor in random_mentors:\n",
    "\n",
    "    vector = create_vector(random_mentors[mentor][\"categories\"] + random_mentors[mentor][\"skills\"] + random_mentors[mentor][\"interests\"])\n",
    "    random_mentors[mentor][\"vector\"]=vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "\n",
    "for mentor in random_mentors:\n",
    "\n",
    "    score=cosine_similarity([create_vector(sample_mentee)], [random_mentors[mentor][\"vector\"]])[0][0]\n",
    "\n",
    "    scores.append({\"mentor\": mentor,\"score\": score})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/samyuktha/PPAI-MatchAPI/workbook.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samyuktha/PPAI-MatchAPI/workbook.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# get top 3 mentors\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/samyuktha/PPAI-MatchAPI/workbook.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m top5\u001b[39m=\u001b[39m\u001b[39msorted\u001b[39m(scores, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m], reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[:\u001b[39m3\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samyuktha/PPAI-MatchAPI/workbook.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m mentor \u001b[39min\u001b[39;00m top5:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/samyuktha/PPAI-MatchAPI/workbook.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     mentor\u001b[39m=\u001b[39mrandom_mentors[mentor[\u001b[39m\"\u001b[39m\u001b[39mmentor\u001b[39m\u001b[39m\"\u001b[39m]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "# get top 3 mentors\n",
    "\n",
    "top5=sorted(scores, key=lambda x: x[\"score\"], reverse=True)[:3]\n",
    "\n",
    "for mentor in top5:\n",
    "    mentor=random_mentors[mentor[\"mentor\"]]\n",
    "    print(mentor[\"categories\"] + mentor[\"skills\"] + mentor[\"interests\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
