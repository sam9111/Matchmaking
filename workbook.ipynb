{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samyuktha/PPAI-MatchAPI/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "categories = [\n",
    "    \"Computer Science\", \"Electrical Engineering\", \"Mechanical Engineering\", \"Civil Engineering\", \"Biomedical Engineering\", \"Environmental Science\", \"Mathematics\", \"Chemistry\", \"Physics\", \"Aerospace Engineering\", \"Data Science\", \"Information Technology\", \"Robotics\", \"Geology\", \"Biochemistry\", \"Education\", \"Environment\", \"Health and Wellness\", \"Social Justice\", \"Poverty Alleviation\", \"Community Development\", \"Humanitarian Aid\", \"Arts and Culture\", \"Elderly Care\", \"Animal Welfare\", \"LGBTQ+ Support\", \"Food Security\", \"Youth Empowerment\", \"Clean Water and Sanitation\", \"Disabilities Support\"\n",
    "]\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Tokenize and encode the categories\n",
    "encoded_categories = [tokenizer(category, return_tensors='pt') for category in categories]\n",
    "\n",
    "# Extract embeddings from BERT\n",
    "category_embeddings = []\n",
    "\n",
    "for category in encoded_categories:\n",
    "    output = model(**category)\n",
    "    embeddings = output.last_hidden_state[:, 0, :]\n",
    "    category_embeddings.append(embeddings)\n",
    "\n",
    "# Convert to torch tensors\n",
    "\n",
    "category_embeddings = torch.cat(category_embeddings, dim=0)\n",
    "\n",
    "# Calculate cosine similarity between categories\n",
    "\n",
    "cosine_similarities = cosine_similarity(category_embeddings.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save top 5 most similar categories for each category without itself to json\n",
    "\n",
    "similar_categories = {}\n",
    "\n",
    "for i in range(len(categories)):\n",
    "\n",
    "    # Sort the categories by similarity\n",
    "    similar_categories[categories[i]] = [categories[x] for x in cosine_similarities[i].argsort()[-6:-1][::-1]]\n",
    "\n",
    "# Save to json\n",
    "\n",
    "import json\n",
    "\n",
    "with open('similar_categories.json', 'w') as fp:\n",
    "    json.dump(similar_categories, fp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import card_data and generate a list of objects with a random name and random categories and random skills and interests under them\n",
    "\n",
    "import random\n",
    "\n",
    "with open('card_data.json') as json_file:\n",
    "\n",
    "    card_data = json.load(json_file)\n",
    "\n",
    "# Generate a list of objects with a random name and random categories and random skills and interests under them\n",
    "\n",
    "random_mentors = {}\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    # Generate a random name\n",
    "    name = \"Mentor \" + str(i)\n",
    "\n",
    "    # Generate random categories\n",
    "    categories = random.sample(list(card_data.keys()), 2)\n",
    "\n",
    "    # Generate random skills and interests\n",
    "    skills = []\n",
    "    interests = []\n",
    "\n",
    "    for category in categories:\n",
    "        skills += random.sample(card_data[category][\"skills\"], 3)\n",
    "        interests += random.sample(card_data[category][\"interests\"], 3)\n",
    "\n",
    "    # Append to random_cards\n",
    "    random_mentors[name] = {\n",
    "        \"categories\": categories,\n",
    "        \"skills\": skills,\n",
    "        \"interests\": interests\n",
    "    }\n",
    "\n",
    "# Save to json\n",
    "\n",
    "with open('random_mentors.json', 'w') as fp:\n",
    "\n",
    "    json.dump(random_mentors, fp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a list of skills/interests/categories, find the most similar mentor from random_mentors\n",
    "\n",
    "# Load random_mentors\n",
    "\n",
    "with open('random_mentors.json') as json_file:\n",
    "\n",
    "    random_mentors = json.load(json_file)\n",
    "\n",
    "sample_mentee=[\n",
    "    \"Computer Science\",\n",
    "    \"Artificial Intelligence\",\n",
    "    \"Cybersecurity\",\n",
    "    \"Machine Learning\",\n",
    "    \"Community Development\",\n",
    "    \"Housing Development\",\n",
    "    \"Infrastructure Improvement\",\n",
    "    \"Affordable Housing\",\n",
    "    \"Data Science\",\n",
    "    \"Data Visualization\",\n",
    "    \"Machine Learning\",\n",
    "    \"Big Data Technologies\",\n",
    "    \"Arts and Culture\",\n",
    "    \"Art Therapy\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('card_data.json') as json_file:\n",
    "\n",
    "    card_data = json.load(json_file)\n",
    "\n",
    "\n",
    "everything = []\n",
    "\n",
    "for category in card_data.keys():\n",
    "    everything.append(category)\n",
    "    everything += card_data[category][\"skills\"]\n",
    "    everything += card_data[category][\"interests\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector(sample):\n",
    "\n",
    "    sample_indices = []\n",
    "\n",
    "    for element in sample:\n",
    "\n",
    "        sample_indices.append(everything.index(element))\n",
    "\n",
    "    # at each index, put 1\n",
    "\n",
    "    sample_vector = [0] * len(everything)\n",
    "\n",
    "    for index in sample_indices:\n",
    "\n",
    "        sample_vector[index] = 1\n",
    "\n",
    "    return sample_vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mentor in random_mentors:\n",
    "\n",
    "    vector = create_vector(random_mentors[mentor][\"categories\"] + random_mentors[mentor][\"skills\"] + random_mentors[mentor][\"interests\"])\n",
    "    random_mentors[mentor][\"vector\"]=vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "\n",
    "for mentor in random_mentors:\n",
    "\n",
    "    score=cosine_similarity([create_vector(sample_mentee)], [random_mentors[mentor][\"vector\"]])[0][0]\n",
    "\n",
    "    scores.append({\"mentor\": mentor,\"score\": score})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Computer Science', 'Community Development', 'Algorithms', 'Web Development', 'Programming', 'Grant Writing', 'Housing Development', 'Community Engagement', 'Computer Vision', 'Machine Learning', 'Cybersecurity', 'Affordable Housing', 'Neighborhood Revitalization', 'Local Empowerment']\n",
      "['Computer Science', 'Community Development', 'Web Development', 'Algorithms', 'Software Development', 'Urban Planning', 'Grant Writing', 'Housing Development', 'Cybersecurity', 'Renewable Energy', 'Machine Learning', 'Affordable Housing', 'Local Empowerment', 'Neighborhood Revitalization']\n",
      "['Computer Science', 'Data Science', 'Software Development', 'Algorithms', 'Data Structures', 'Machine Learning', 'Data Analysis', 'Big Data Technologies', 'Cybersecurity', 'Computer Vision', 'Renewable Energy', 'Data Mining', 'Data Ethics', 'Predictive Analytics']\n"
     ]
    }
   ],
   "source": [
    "# get top 3 mentors\n",
    "\n",
    "top5=sorted(scores, key=lambda x: x[\"score\"], reverse=True)[:3]\n",
    "\n",
    "for mentor in top5:\n",
    "    mentor=random_mentors[mentor[\"mentor\"]]\n",
    "    print(mentor[\"categories\"] + mentor[\"skills\"] + mentor[\"interests\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
